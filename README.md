# project-comparative-study-adversarial-attacks-ead-square

This paper explores the effectiveness of various adversarial attack methods on deep learning models, focusing on their implications for cybersecurity. We compare the performance of Elastic-Net Attacks to Deep Neural Networks (EADL1 and EADEN) and the Square Attack against three widely used architectures: Vanilla CNN, ResNet-18, and VGG11, trained on the CIFAR-10 dataset. By evaluating these attacks under default and tweaked parameter settings, we provide insights into their relative effectiveness and the underlying reasons for their success or failure. The study demonstrates that parameter adjustments can significantly impact the attack success rates (ASR), with variations across different models. Our findings highlight the inherent vulnerabilities in neural networks and underscore the necessity for robust defense mechanisms in cybersecurity applications. Additionally, we discuss potential defenses, the practical implications of our results in the cybersecurity domain, and the limitations of our study. This research contributes to the understanding of adversarial machine learning, emphasizing the critical need for enhanced security measures to protect AI systems from adversarial threats.
